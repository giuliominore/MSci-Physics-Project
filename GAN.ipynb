{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GAN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"JPlIw39cSGdk"},"source":["import numpy as np\n","import tensorflow as tf\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow.keras.layers import Dense,BatchNormalization,LeakyReLU,Reshape,Conv2DTranspose,Conv2D,Dropout,Dense,Flatten\n","import time\n"," \n","from IPython import display\n"," \n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eLnJrDkSVCq"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqL3s4ubSGdu"},"source":["#import and preprocess data\n","training_images=np.load(\"drive/My Drive/LArTPCdata/SupernovaImages.npy\")\n","\n","training_images = training_images.reshape(len(training_images), 48, 48, 1)\n","norm=np.amax(training_images)/2\n","training_images = (training_images - norm) / norm # Normalize the images to [-1, 1]\n","\n","# Shuffle and batch the data (to fit in memory)\n","buffer_size = len(training_images)\n","batch_size = 64\n","training_dataset = tf.data.Dataset.from_tensor_slices(training_images).shuffle(buffer_size).batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFnslaiYSGdu"},"source":["def generator_model():\n","    '''\n","    produce image from a seed\n","    Dense layer takes seed as input and upsamples several times until an image of size 48x48 is achieved\n","    Conv2DTranspose: upsampling layer, \"deconvolution\", going from output to input\n","    LeakyReLU activation for layers (to avoid dead neurons) except tanh for final layer'''\n","    model = tf.keras.Sequential()\n","    model.add(Dense(12*12*256, use_bias=False, input_shape=(48,)))\n","    model.add(BatchNormalization()) #normalize inputs\n","    model.add(LeakyReLU()) #used for sparse gradients (signal not strong enough for weigths to be tuned)\n","\n","    model.add(Reshape((12, 12, 256)))\n","    assert model.output_shape == (None, 12, 12, 256)\n","\n","    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 12, 12, 128)\n","    model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","\n","    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 24, 24, 64)\n","    model.add(BatchNormalization())\n","    model.add(LeakyReLU())\n","\n","    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n","    assert model.output_shape == (None, 48, 48, 1)\n","\n","    return model\n","\n","\n","generator = generator_model()\n","\n","noise = tf.random.normal([1, 48])\n","generated_image = generator(noise, training=False)\n","\n","plt.imshow(generated_image[0, :, :, 0], cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SkSt98j_SGdw"},"source":["def discriminator_model():\n","    '''standard CNN\n","    output positive values for real images\n","    output negative values for fake images'''\n","    model = tf.keras.Sequential()\n","    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[48, 48, 1]))\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3)) #sets inputs to zero at rate given, to avoid overfitting. Other inputs are scaled up so total sum is unchanged\n","\n","    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU())\n","    model.add(Dropout(0.3)) \n","\n","    model.add(Flatten())\n","    model.add(Dense(1))\n","\n","    return model\n","\n","\n","discriminator = discriminator_model()\n","#generated images have to be run htrough discriminator to see if they have fooled it\n","decision = discriminator(generated_image)\n","print (decision)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVrO18-lSGdx"},"source":["#define cross entropy loss\n","cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","def discriminator_loss(real_output, fake_output):\n","    '''quantify how well the discriminator categorises images\n","    compares predictions on real images to an array of ones\n","    and on fake generated images to an array of zeros'''\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    return real_loss + fake_loss\n","    \n","\n","def generator_loss(fake_output):\n","    '''quantify how well the discriminator was fooled. \n","    A generator performing well means the discriminator classifies generated images as 1\n","    compare discriminator output on fake images to array of ones\n","    '''\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpm0CGlQSGdx"},"source":["noise_dim = 48 #due to size of images\n","num_examples_to_generate = 9 #represents the number of pictures displayed at each epoch\n","\n","seed = tf.random.normal([num_examples_to_generate, noise_dim])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmoOUoNYSGdy"},"source":["#create two generators to train network parameters separately\n","generator_optimizer = tf.keras.optimizers.Adam(0.001)\n","discriminator_optimizer = tf.keras.optimizers.Adam(0.001)\n","\n","#create a checkpoint to save the model parameters if the training is stopped\n","checkpoint_dir = 'drive/My Drive/GAN'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)\n","\n","\n","\n","@tf.function #to compile function\n","def train_step(images):\n","    '''\n","    take random seed as input and produce image\n","    discriminator classifies real (dataset) and fake (generated) images\n","    calculates loss, and uses gradients to update generator and discriminator parameters\n","    '''\n","    noise = tf.random.normal([batch_size, noise_dim])\n","\n","    #Records operations for automatic differentiation\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","\n","        #generate images\n","        generated_images = generator(noise, training=True)\n","\n","        #discriminate real and fake images\n","        real_output = discriminator(images, training=True)\n","        fake_output = discriminator(generated_images, training=True)\n","\n","        #calculate loss\n","        gen_loss = generator_loss(fake_output)\n","        disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    #calculate gradients\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","    #apply gradients to the model parameters\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-C-Oc3sSGdy"},"source":["def train(dataset, epochs):\n","  '''function to run multiple training steps sequentially'''\n","    for epoch in range(epochs):\n","        start = time.time()\n","\n","        #perform a training step on batches of data\n","        for image_batch in dataset:\n","            train_step(image_batch)\n","\n","        # produce image for display\n","        display.clear_output(wait=True)\n","        generate_and_display_images(generator, epoch + 1, seed)\n","\n","        # Save the model every 50 epochs\n","        if (epoch + 1) % 50 == 0:\n","          checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n","\n","    # Generate display after the final epoch\n","    display.clear_output(wait=True)\n","    generate_and_display_images(generator, epochs, seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luOlIkUfSGdy"},"source":["def generate_and_display_images(model, epoch, test_input):\n","\n","    #training set to false so that prediction on an image does not change parameters for others\n","    predictions = model(test_input, training=False)\n","\n","    fig = plt.figure(figsize=(3,3))\n","\n","    for i in range(predictions.shape[0]):\n","        plt.subplot(3, 3, i+1)\n","        plt.imshow(predictions[i, :, :, 0] * norm + norm)\n","        plt.axis('off')\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWhk9zWhscFd"},"source":["#restore last saved checkpoint if training is stopped at some point\n","\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IC7tl_rSGdz"},"source":["EPOCHS = 2000\n","#4000 epochs already run\n","train(training_dataset, EPOCHS)"],"execution_count":null,"outputs":[]}]}